{
  "title": "Makine öğrenmesi",
  "content": "Makine öğrenimi (ML), veriden öğrenebilen ve görünmeyen verilere genelleştirebilen ve dolayısıyla açık talimatlar olmadan görevleri yerine getirebilen istatistiksel algoritmaların geliştirilmesi ve incelenmesiyle ilgilenen, yapay zekâda akademik bir disiplindir. Makine öğrenimi, bilgisayarların deneyimlerinden öğrenerek karmaşık görevleri otomatikleştirmeyi sağlayan bir yapay zeka alanıdır. Bu, veri analizi yaparak örüntüler tespit etme ve tahminlerde bulunma yeteneğine dayanır. Son zamanlarda yapay sinir ağları, performans açısından önceki birçok yaklaşımı geride bırakmayı başardı.\nMakine öğrenimi yaklaşımları, doğal dil işleme, bilgisayar görüşü, konuşma tanıma, e-posta filtreleme, tarım ve tıp dahil olmak üzere birçok alana uygulanmıştır. Bu teknikler, genellikle tahmine dayalı analitik olarak tanımlanan iş sorunlarına yönelik uygulamalarda önemli bir rol oynamaktadır. ML, iş sorunlarına yönelik uygulamasında tahmine dayalı analitik denir. Makine öğreniminin tümü istatistiksel temelli olmasa da, hesaplamalı istatistiksel yöntemlerinin önemli bir kaynağıdır.\nML'nin matematiksel temelleri matematiksel optimizasyon (matematiksel programlama) yöntemleriyle sağlanır. Veri madenciliği, gözetimsiz öğrenme yoluyla keşifsel veri analizine (EDA) odaklanan ilgili (paralel) bir bilim dalıdır.\nTeorik bir bakış açısından bakıldığında, muhtemelen yüksek olasılıklı doğru (PAC) öğrenme, makine öğrenimini tanımlamak için bir çerçeve sağlar.\nMakine öğrenimi araştırmalarının odaklandığı konu bilgisayarlara karmaşık örüntüleri algılama ve veriye dayalı akılcı kararlar verebilme becerisi kazandırmaktır. Bu, makine öğreniminin istatistik, olasılık kuramı, veri madenciliği, örüntü tanıma, yapay zekâ, uyarlamalı denetim ve kuramsal bilgisayar bilimi gibi alanlarla yakından ilintili olduğunu gösterir.\n\n\n== Özet ==\nMakine öğrenimi, bilgisayarların, açıkça programlanmadan karmaşık görevleri otomatikleştirmeyi öğrenmelerini sağlar. Belirli görevleri yerine getirmeleri için sağlanan verilerdeki örüntüleri ve ilişkileri keşfederek bu örüntüleri yeni durumlara uygulama yeteneği kazandırır. Bilgisayarlara atanan basit görevler için, makineye eldeki sorunu çözmek için gereken tüm adımları nasıl uygulayacağını bildiren algoritmalar programlamak mümkündür; bilgisayar tarafında öğrenmeye gerek yoktur. Daha gelişmiş görevlerde insan için gerekli algoritmaları elle yapmak zor olabilir. Uygulamada, insan programcıların gerekli her adımı belirlemesinden ziyade, makinenin kendi algoritmasını geliştirmesine yardımcı olmak daha etkili olabilir.\nMakine öğrenimi disiplini, bilgisayarlara tam olarak tatmin edici bir algoritmanın bulunmadığı görevleri gerçekleştirmeyi öğretmek için çeşitli yaklaşımlar kullanır. Çok sayıda olası yanıtın olduğu durumlarda, doğru yanıtlardan bazılarını geçerli olarak etiketlemek bir yaklaşımdır. Bu, daha sonra bilgisayarın doğru yanıtları bulmak için kullandığı algoritmayı/algoritmaları geliştirmede eğitim verisi olarak kullanılabilir. Örneğin, sayısal karakter tanıma görevinde sistemi eğitmek için el yazısıyla yazılmış rakamların MNIST veri kümesi sıklıkla kullanılır.\n\n\n== Tarihçe ==\nMakine öğrenimi terimi 1959'da bilgisayar oyunları ve yapay zeka alanında öncü ve IBM çalışanı olan Amerikalı Arthur Samuel tarafından icat edildi. 1960'larda makine öğrenimi araştırmasının temsili bir kitabı, Nilsson'un Öğrenme Makineleri hakkındaki kitabıydı ve çoğunlukla örüntü sınıflandırması için makine öğrenimi ile ilgiliydi. Model tanıma ile ilgili ilgi, 1973'te Duda ve Hart tarafından tanımlandığı gibi 1970'lerde de devam etti.\n1981'de, bir sinir ağı 'nın bilgisayar terminalinden 40 karakteri (26 harf, 10 rakam ve 4 özel sembol) tanımayı öğrenmesi için öğretme stratejilerinin kullanımına ilişkin bir rapor verildi.\nTom M. Mitchell, makine öğrenimi alanında incelenen algoritmaların geniş ölçüde alıntılanan daha resmi bir tanımını yaptı: \"Bir bilgisayar programının performans ölçüsü \"P\" ve bazı \"T\" görev sınıflarıyla ilgili olarak \"T\" görevlerindeki performansı \"E\" deneyimiyle iyileşiyorsa \"P\" ile ölçüldüğü gibi E deneyiminden öğrendiği söylenir.\nMakine öğreniminin söz konusu olduğu görevlerin bu tanımı, alanı bilişsel terimlerle tanımlamak yerine temelde operasyonel tanım sunar. Bu, Alan Turing'in \"Computing Machinery and Intelligence\" adlı makalesinde \"Makineler düşünebilir mi?\" \"Makineler bizim (düşünen varlıklar olarak) yapabildiğimizi yapabilir mi?\" sorusuyla değiştirilir.\nGünümüzün modern makine öğreniminin iki amacı vardır, biri verileri geliştirilen modellere göre sınıflandırmak, diğer amaç ise bu modellere dayalı olarak gelecekteki sonuçlar için tahminler yapmaktır. Verileri sınıflandırmaya özgü varsayımsal bir algoritma, kanserli benleri sınıflandırmada onu eğitmek için denetimli öğrenmeyle birleştirilen mollerin bilgisayar görüşü kullanabilir. Hal böyle olunca, hisse senedi ticareti için makine öğrenme algoritması, tüccara gelecekteki olası tahminler hakkında bilgi verebilir.\n\n\n== Diğer alanlarla ilişkiler ==\n\n\n=== Yapay zeka ===\n\nBilimsel bir çaba olarak makine öğrenimi, yapay zeka arayışından doğdu. Yapay zekanın akademik disiplin olarak ilk günlerinde bazı araştırmacılar makinelerin verilerden öğrenmesini sağlamakla ilgileniyordu. Soruna çeşitli sembolik yöntemlerle ve daha sonra \"sinir ağları\" denilen yöntemlerle yaklaşmaya çalıştılar; bunlar çoğunlukla perceptronlar ve diğer modellerdi daha sonra istatistiklerin genelleştirilmiş doğrusal modellerin yeniden icatları oldukları anlaşıldı.\nOlasılık muhakeme de özellikle otomatik tıbbi tanı için kullanıldı. Ancak, mantıksal, bilgiye dayalı yaklaşım üzerindeki artan vurgu, yapay zeka ile makine öğrenimi arasında bir sürtüşmeye neden oldu. Olasılıklı sistemler, veri toplama ve gösteriminin teorik ve pratik problemleriyle boğuşuyordu.\n1980 yılına gelindiğinde, uzman sistemler yapay zekaya hâkim oldu ve istatistik gözden düştü.\nSembolik/bilgiye dayalı öğrenme üzerine çalışmalar AI içinde devam etti ve endüktif mantık programlama'ya yol açtı ancak daha istatistiksel araştırma hattı artık örüntü tanıma da ve bilgi erişimdeydi.\nSinir ağları araştırması, yapay zeka ve bilgisayar bilimi tarafından aynı zamanlarda terk edildi. Bu çizgi de diğer disiplinlerden John Hopfield, Rumelhart ve Hinton‘i içeren araştırmacılar tarafından AI/CS alanının dışında \"bağlantısallık\" olarak devam ettirildi. Ana başarıları, 1980'lerin ortasında geri yayılımın yeniden buluşuyla ortaya çıktı.\nAyrı bir alan olarak yeniden düzenlenen makine öğrenimi (ML), 1990'larda gelişmeye başladı. Alan, amacını yapay zeka elde etmekten ziyade pratik nitelikteki çözülebilir problemlerle mücadele etmek olarak değiştirdi. Odağı, AI'dan miras aldığı sembolik yaklaşımlar'dan, istatistik ve olasılık teorisi’nden ödünç alınan yöntem ve modellere kaydırdı.\n2020 itibarıyla birçok kaynak, makine öğreniminin yapay zekanın bir alt alanı olmaya devam ettiğini iddiasını sürdürüyor.\nAna anlaşmazlık, tüm makine öğreniminin Yapay zeka(YZ)'nın (AI) bir parçası olup olmadığıdır çünkü bu, makine öğrenimini kullanan herhangi birinin YZ kullandığını iddia edebileceği anlamına gelir. Diğerlerinin görüşü, tüm makine öğreniminin yapay zekanın bir parçası olmadığıdır ki burada, makine öğreniminin yalnızca 'akıllı' bir alt kümesi YZ'nin bir parçasıdır.\nMakine öğrenimi ve yapay zeka arasındaki farkın ne olduğu sorusu, \"The Book of Why\" adlı kitabında Judea Pearl tarafından yanıtlanır. Buna göre, makine öğrenimi pasif gözlemlere dayanarak öğrenir ve tahmin eder, oysa AI, hedeflerine başarılı bir şekilde ulaşma şansını en üst düzeye çıkaran eylemleri öğrenmek ve gerçekleştirmek için çevre ile etkileşime giren aracı ifade eder.\n\n\n=== Veri sıkıştırma ===\nMakine öğrenimi ile sıkıştırma arasında yakın bir bağlantı vardır. Tüm geçmişi göz önüne alındığında bir dizinin sonsal olasılıklarını tahmin eden bir sistem, optimum veri sıkıştırması için (çıkış dağılımında aritmetik kodlama kullanılarak) kullanılabilir. Tersine, tahmin için en uygun sıkıştırıcı (önceki geçmiş göz önüne alındığında en iyi sıkıştıran sembolü bularak) kullanılabilir. Bu eşdeğerlik, veri sıkıştırmanın \"genel zeka\" için ölçüt olarak kullanılmasının gerekçesi olarak kullanılmıştır.\nAlternatif bir görünüm, sıkıştırma algoritmalarının dizeleri örtülü özellik alanı vektörlerine örtülü olarak eşlediğini gösterebilir ve sıkıştırmaya dayalı benzerlik ölçümleri, bu özellik alanlarındaki benzerliği hesaplar. Her sıkıştırıcı C(.) için ilişkili bir vektör uzayı ℵ tanımlarız, öyle ki C(.), ||~x|| vektör normuna karşılık gelen giriş dizesi x'i eşler. Tüm sıkıştırma algoritmalarının altında yatan özellik uzaylarının kapsamlı incelemesi uzay nedeniyle engellenir; bunun yerine, özellik vektörleri üç temsili kayıpsız sıkıştırma yöntemini yani LZW, LZ77 ve PPM'yi incelemeyi seçer.\nHutter Ödülü'nde daha doğrudan açıklanan bir bağlantı olan AIXI teorisine göre, x'in mümkün olan en iyi sıkıştırılması, x'i üreten mümkün olan en küçük yazılımdır. Örneğin, bu modelde bir zip dosyasının sıkıştırılmış boyutu hem zip dosyasını hem de zip açma yazılımını içerir. Çünkü her ikisi olmadan zip dosyasını açamazsınız ancak daha da küçük birleştirilmiş bir form olabilir.\nYapay zeka destekli ses/video sıkıştırma yazılımı örnekleri olarak VP9, NVIDIA Maxine, AIVC, AccMPEG sayılabilir. Yapay zeka destekli görüntü sıkıştırma gerçekleştirebilen yazılımına OpenCV, TensorFlow, MATLAB'ın Image Processing Toolbox (IPT) ve High-Fidelity Generative Image Compression örnek olarak verilebilir.\nDenetimsiz makine öğreniminde, benzer veri noktalarını kümeler halinde gruplandırarak verileri sıkıştırmak için k-ortalama kümelemesi kullanılabilir. Bu teknik, önceden tanımlanmış etiketlerin bulunmadığı kapsamlı veri kümelerinin işlenmesini basitleştirir ve görüntü sıkıştırma gibi alanlarda çok kullanılır.\nGeniş dil modelleri aynı zamanda kayıpsız veri sıkıştırma özelliğiklidir.\n\n\n=== Veri madenciliği ===\nMakine öğrenimi ve veri madenciliği sıklıkla aynı yöntemleri kullanır ve önemli ölçüde örtüşür, ancak makine öğrenimi, eğitim verilerinden öğrenilen bilinen özelliklere dayalı olarak tahmine odaklanırken, veri madenciliği verilerdeki (daha önce) bilinmeyen özelliklerin keşfedilmesine odaklanır (bu, veritabanlarında bilgi keşfinin analiz adımıdır).\nVeri madenciliği farklı amaçlarla birçok makine öğrenimi yöntemini kullanır. Öte yandan makine öğrenimi, \"denetimsiz öğrenme\" olarak veya öğrenen doğruluğunu artırmak için bir ön işleme adımı olarak veri madenciliği yöntemlerini de kullanır. Bu iki araştırma topluluğu (çoğunlukla ayrı konferansları ve ayrı dergileri olan, ECML PKDD önemli bir istisnadır) arasındaki kafa karışıklığının büyük kısmı, birlikte çalıştıkları temel varsayımlardan kaynaklanmaktadır: Makine öğreniminde performans genellikle bilinen bilgiyi yeniden üretme becerisine göre değerlendirilirken, bilgi keşfi ve veri madenciliği (KDD)'de temel görev önceden bilinmeyen bilginin keşfidir. Bilinen bilgilere göre değerlendirildiğinde, bilgi verilmeyen (denetlenmeyen) bir yöntem, diğer denetlenen yöntemlere göre kolayca daha iyi performans gösterecektir, oysa tipik bir KDD görevinde, eğitim verilerinin mevcut olmaması nedeniyle denetlenen yöntemler kullanılamaz.\nMakine öğreniminin optimizasyonla da yakın bağları vardır: birçok öğrenme problemi, eğitim set örneklerinde bazı kayıp fonksiyonların en aza indirilmesi olarak formülleştirilir. Kayıp fonksiyonları, eğitilen modelin tahminleri ile gerçek problem örnekleri arasındaki tutarsızlığı ifade eder (örneğin, sınıflandırmada örneklere bir etiket atamak istenir ve modeller, bir dizi örnek için önceden atanmış etiketleri doğru şekilde tahmin edecek şekilde eğitilir).\n\n\n=== Genelleme ===\nOptimizasyon ve makine öğrenimi arasındaki fark, genelleştirme hedefinden kaynaklanır: Optimizasyon algoritmaları bir eğitim setindeki kaybı en aza indirebilirken, makine öğrenimi, görünmeyen örneklerdeki kaybı en aza indirmekle ilgilenir. Çeşitli öğrenme algoritmalarının genelleştirilmesinin karakterize edilmesi, özellikle derin öğrenme algoritmaları için güncel araştırmaların aktif bir konusudur.\n\n\n=== İstatistik ===\nMakine öğrenimi ve istatistik, yöntemler açısından birbiriyle yakından ilişkili alanlardır ancak temel hedefleri bakımından farklıdır: istatistik bir örnekten nüfus çıkarımları yaparken, makine öğrenimi genelleştirilebilir tahmin kalıpları bulur. Michael I. Jordan'a göre, metodolojik ilkelerden teorik araçlara kadar makine öğrenimi fikirlerinin istatistik alanında uzun bir geçmişi vardır. Ayrıca genel alanı adlandırmak için veri bilimi terimini yer tutucu olarak önerdi.\nGeleneksel istatistiksel analizler, çalışma veri seti için en uygun modelin önsel seçimini gerektirir. Ayrıca analize yalnızca önceki deneyimlere dayanan önemli veya teorik olarak ilgili değişkenler dahil edilir. Bunun aksine, makine öğrenimi önceden yapılandırılmış bir model üzerine kurulmamıştır; bunun yerine veriler, altta yatan kalıpları tespit ederek modeli şekillendirir. Modeli eğitmek için ne kadar çok değişken (girdi) kullanılırsa nihai model o kadar doğru olur.\nLeo Breiman iki istatistiksel modelleme paradigmasını birbirinden ayırdı: veri modeli ve algoritmik model,; burada \"algoritmik model\", Rastgele orman gibi az çok makine öğrenimi algoritmaları anlamına gelir.\nBazı istatistikçiler, makine öğreniminden yöntemleri benimseyerek istatistiksel öğrenme adını verdikleri birleşik bir alana yol açtılar.\n\n\n=== İstatistiksel fizik ===\nDüzensiz sistemlerin köklü fiziğinden türetilen analitik ve hesaplamalı teknikler, örneğin derin sinir ağ'larının ağırlık uzayını analiz etmek için makine öğrenimi de dahil olmak üzere büyük ölçekli sorunlara genişletilebilir. İstatistiksel fizik bu nedenle tıbbi teşhis alanında da uygulama alanları bulmaktadır.\n\n\n== Teori ==\nBir öğrencinin temel amacı, deneyiminden genelleme yapmaktır.  Bu bağlamda genelleme, öğrenen bir makinenin, bir öğrenme veri kümesini deneyimledikten sonra yeni, görülmemiş örnekler/görevler üzerinde doğru bir şekilde performans gösterme yeteneğidir. Eğitim örnekleri, genel olarak bilinmeyen bazı olasılık dağılımlarından gelir (oluşma uzayını temsil ettiği kabul edilir) ve öğrencinin, yeni durumlarda yeterince doğru tahminler üretmesini sağlayan bu alan hakkında genel bir model oluşturması gerekir. Bu bağlamda genelleme, öğrenen bir makinenin, bir öğrenme veri kümesini deneyimledikten sonra yeni, görülmemiş örnekler/görevler üzerinde doğru şekilde performans gösterme yeteneğidir. Eğitim örnekleri, genel olarak bilinmeyen bazı olasılık dağılımlarından gelir (oluşma uzayını temsil ettiği kabul edilir) ve öğrencinin, yeni durumlarda yeterince doğru tahminler üretmesini sağlayan bu alan hakkında genel bir model oluşturması gerekir.\nMakine öğrenimi algoritmalarının ve performanslarının hesaplamalı analizi, Yüksek Olasılıklı Doğru Öğrenme (PAC) modeli aracılığıyla hesaplamalı öğrenme teorisi olarak bilinen teorik bilgisayar biliminin bir dalıdır. Eğitim kümeleri sınırlı olduğundan ve gelecek belirsiz olduğundan, öğrenme teorisi genellikle algoritmaların performansına dair garanti vermez. Bunun yerine performansa ilişkin olasılıksal sınırlar oldukça yaygındır. Önyargı-varyans ayrıştırması, genelleme hatasını ölçmenin bir yoludur.\nGenelleme bağlamında en iyi performansı elde etmek için hipotezin karmaşıklığı, verilerin altında yatan işlevin karmaşıklığıyla eşleşmelidir. Hipotezin fonksiyondan daha az karmaşık olması durumunda model, verilere gereğinden az uyum sağlamıştır. Yanıt olarak modelin karmaşıklığı artarsa eğitim hatası azalır. Ancak hipotez çok karmaşıksa, model aşırı uyumdan etkilenir ve genelleme daha zayıf olur.\nPerformans sınırlarına ek olarak, öğrenme teorisyenleri öğrenmenin zaman karmaşıklığını ve fizibilitesini de inceler. Hesaplamalı öğrenme teorisinde, bir hesaplamanın polinom zamanında yapılması mümkünse mümkün olduğu kabul edilir. İki tür zaman karmaşıklık sonucu vardır: Pozitif sonuçlar, belirli bir fonksiyon sınıfının polinom zamanda öğrenilebileceğini gösterir. Negatif sonuçlar bazı sınıfların polinom zamanında öğrenilemeyeceğini göstermektedir.\n\n\n== Uygulamalar ==\nMakine öğreniminin başlıca uygulamaları makine algılaması, bilgisayarlı görme, doğal dil işleme, sözdizimsel örüntü tanıma, arama motorları, tıbbi tanı, biyoinformatik, beyin-makine arayüzleri ve kiminformatik, kredi kartı dolandırıcılığı denetimi, borsa çözümlemesi, DNA dizilerinin sınıflandırılması, konuşma ve elyazısı tanıma, bilgisayarlı görmede nesne tanıma, oyun oynama, yazılım mühendisliği, uyarlamalı web siteleri ve robot gezisidir.\n\n\n== İnsan etkileşimi ==\nMakine öğrenimi sistemlerinin bir bölümü insan sezgisine olan gereksinimi tümüyle ortadan kaldırmaya çalışırken bazıları insan ve makine arasında işbirliğine dayalı bir yaklaşım benimsemektedir. Ne var ki, sistemi tasarlayan kişinin verinin kodlanma biçimi üzerinde tümüyle egemen oluşu insan sezgisinin tümüyle ortadan kaldırılmasını olanaksızlaştırmaktadır. Makine öğrenimi deneysel yöntemin otomatikleştirilmesi çabası olarak görülmektedir.\nBazı istatistiksel makine öğrenimi araştırmacıları Bayes istatistiği çerçevesi kapsamında kullanılabilen yöntemler geliştirmektedirler.\n\n\n== Öğrenme yaklaşımları ==\nMakine öğrenimi algoritmaları hedeflenen sonuca göre birkaç sınıfa ayrılabilmektedir:\n\nGözetimli öğrenme - Gözetimli öğrenme, bilgisayarların etiketlenmiş örnek verilerden öğrenme yeteneğini içerir. Bu yaklaşım, her örneğin bir girdi ve ona karşılık gelen bir çıktıya sahip olduğu durumlar için idealdir. Örneğin, bir görüntünün üzerindeki nesnelerin tanımlanması gibi bir problemde, etiketlenmiş veri setleri kullanılır. Makine, bu veri setlerini analiz ederek girdileri çıktılara eşleme yeteneğini geliştirir.\nGözetimsiz öğrenme - Gözetimsiz öğrenme, bilgisayarların etiketlenmemiş verilerden örüntüleri keşfetme yeteneğini içerir. Bu yaklaşım, verilerdeki yapıları anlamak ve veri setlerindeki gizli ilişkileri keşfetmek için kullanılır. Örneğin, bir pazarlama analizi yapılırken, müşteri segmentlerini belirlemek için gözetimsiz öğrenme teknikleri kullanılabilir. Bu sayede, belirli bir önceden tanımlanmış etikete gerek kalmadan veri setindeki doğal gruplamaları keşfedebiliriz.\nPekiştirmeli öğrenme - Pekiştirmeli öğrenme, bir ajanın çevresiyle etkileşime girerek deneme-yanılma yoluyla optimal davranışı öğrenme yeteneğini içerir. Bu yaklaşım genellikle karar alma ve kontrol problemleri için kullanılır. Ajan, bir ortamda belirli eylemler gerçekleştirir ve bu eylemlerin sonuçlarına göre ödüller veya cezalar alır. Bu ödüller ve cezalar, ajanın davranışını optimize etmesine yardımcı olur. Örneğin, bir robotun belirli bir ortamda dengede kalmasını öğrenmesi veya bir oyun oynarken en yüksek skoru elde etmesi için pekiştirmeli öğrenme kullanılabilir.\nYarı gözetimli öğrenme - Uygun işlev ya da sınıflandırıcılar oluşturmak için etiketli ve etiketsiz örnekleri birlikte ele alır.\nÖğrenmeyi öğrenme - Önceki deneyimlerden yararlanır. \n\n\n== Ayrıca bakınız ==\n\n\n== Kaynakça ==\n\n\n== Konuyla ilgili yayınlar ==\n\n\n== Dış bağlantılar ==\n\"Makine öğrenimi algoritmalarının Ruby uygulamaları\". 25 Haziran 2012 tarihinde kaynağından arşivlendi. \n\"Andrew Ng'in Stanford ders notları\". 31 Ağustos 2009 tarihinde kaynağından arşivlendi. \n\"Berimsel Zekâ Ansiklopedisi\". 11 Ekim 2007 tarihinde kaynağından arşivlendi. \n\"Uluslararası Makine Öğrenimi Topluluğu\". 9 Mart 2012 tarihinde kaynağından arşivlendi. \n\"Makine öğrenimi, veri madenciliği ve KDD bilimsel konferansları\". 3 Eylül 2009 tarihinde kaynağından arşivlendi. \n\"Açık kaynak kodlu makine öğrenimi yazılımları\". 3 Ekim 2009 tarihinde kaynağından arşivlendi. \n\"Görüntülü makine öğrenimi dersleri\". 16 Eylül 2009 tarihinde kaynağından arşivlendi. \n\"Berimsel Zekâ ve Makine Öğrenimi Sanal Topluluğu\". 4 Ekim 2009 tarihinde kaynağından arşivlendi."
}